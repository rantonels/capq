<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>CAPQ</title>
  <style type="text/css">code{white-space: pre;}</style>
  <!--[if lt IE 9]>
    <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->
  <link rel="stylesheet" href="style/markdown5.css">
  <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<!--<script src="js/jquery-1.11.3.js"></script>
<script src="js/jquery.feyn-1.0.1.min.js"></script>--!>
</head>
<body>
<div class="version">
commit fe49607472ba283262ff706bdefcca569ac99897
Author: Riccardo Antonelli <riccardo.antonelli@hotmail.it>
Date:   Mon Jul 6 14:51:02 2015 +0200
</div>
<h2 class="pretitle">the handy booklet of</h2>
<h1 class="bigtitle">Constantly Asked <br>Physics Questions</h1>

<p>Everyone gets bored of always answering the same questions over and over again. It's normal. Especially if it's Physics. That's why we have FAQs. But next to the <em>always</em> asked questions, there are also the <em>often</em> asked, those who just can not make it to big FAQs but really are popular enough to annoy the answerer, helplessly scrolling for new adventures in a sea of d&eacute;j&agrave;-vus.</p>

<p>This is not a definitive FAQ, nor is it necessarily a good FAQ, it's just my FAQ. It's shamelessly skewed towards my view of the physical world. It is also very inconsistent in the level requested of the reader. Typically, I'd just assume the minimal background needed for the answer to be a pleasurable conversation, neither a patronizing poem nor a bored review.</p>

<p>You can contribute if you want! Check the <a href="https://github.com/rantonels/capq">README at the Github project page</a> or just <a href="https://reddit.com/u/rantonels">hit me up on Reddit</a>.</p>

<p><small>(The stylesheet for this webpage is markdown5.css by jasonm23 (<a href="https://github.com/jasonm23/markdown-css-themes">Github</a>))</small></p>

<h2>Download .pdf</h2>

<p>You can find a printable, up-to-date .pdf version of the CAPQ <a href="tex/capq-booklet.pdf">here</a>. (This .pdf is a work in progress and content might be scrambled, missing, or badly laid out.)<p>

<h2>Index</h2>

<p>To link to one of the answers, right click and copy the url from the corresponding link below.</p>


<nav id="TOC">
<ul>
<li><a href="#KGP">Kinematics/General Physics</a><ul>
<li><a href="#KGP1">KGP1 - Why is <span class="math">\(c\)</span>/<span class="math">\(\hbar\)</span>/<span class="math">\(k_B\)</span>/(other fundamental constant) the value it is? What would happen if it was different?</a></li>
</ul></li>
<li><a href="#CM">Classical Mechanics</a><ul>
<li><a href="#CM1">CM1 - Why is my physics teacher so anal about centripetal vs centrifugal? Is the centrifugal force &quot;fictitious&quot;?</a></li>
</ul></li>
<li><a href="#TD">Thermodynamics</a></li>
<li><a href="#OM">Celestial/Orbital Mechanics</a></li>
<li><a href="#FM">Fluid Mechanics</a></li>
<li><a href="#CED">Classical Electrodynamics</a><ul>
<li><a href="#CED1">CED1 - What is the Maxwell stress tensor <span class="math">\(\mathbf{\sigma}\)</span> and how does it work?</a></li>
<li><a href="#CED2">CED2 - Why is current produced to a wire when moving a magnet close to it?</a></li>
</ul></li>
<li><a href="#AM">Analytical Mechanics</a><ul>
<li><a href="#AM1">AM1 - Why are <span class="math">\(q(t)\)</span> and <span class="math">\(\dot q(t)\)</span> treated as indipendent in Lagrangian mechanics? Shouldn't <span class="math">\(\dot q(t)\)</span> be viewed as a function(al) of <span class="math">\(q(t)\)</span>?</a></li>
</ul></li>
<li><a href="#SR">Special Relativity</a><ul>
<li><a href="#SR1">SR1 - In what sense does <span class="math">\(E=mc^2\)</span>, and what does it mean?</a></li>
<li><a href="#SR2">SR2 - if photons are massless, how can <span class="math">\(E=mc^2\)</span>?</a></li>
</ul></li>
<li><a href="#GR">General Relativity</a></li>
<li><a href="#QM">Quantum Mechanics</a></li>
<li><a href="#QFT">General Quantum Field Theory/Many Body/Relativistic QM</a></li>
<li><a href="#NP">Nuclear Physics</a></li>
<li><a href="#QED">Quantum Electrodynamics</a><ul>
<li><a href="#QED1">QED1 - How does <span class="math">\(1+2+3+\ldots=-1/12\)</span>/<span class="math">\(\zeta\)</span>-regularization enter in the Casimir effect?</a></li>
</ul></li>
<li><a href="#HEP">Particle Physics/High Energy Physics</a><ul>
<li><a href="#HEP1">HEP1 - Why are photons massless?</a></li>
<li><a href="#HEP2">HEP2 - Why do photons not acquire a mass through the Higgs mechanism?</a></li>
<li><a href="#HEP3">HEP3 - Why do photons not acquire a mass through quantum corrections/interaction with virtual particles? What is charge renormalization?</a></li>
</ul></li>
<li><a href="#QG">Quantum Gravity/String Theory</a><ul>
<li><a href="#QG1">QG1 - If the Planck length/Planck time is the smallest measurable/possible length/time, then...?</a></li>
</ul></li>
<li><a href="#list-of-well-known-crackpots">List of well-known crackpots</a><ul>
<li><a href="#aether-wave-theory-zephir">Aether Wave Theory / Zephir</a></li>
<li><a href="#imagining-the-tenth-dimension-rob-bryanton">Imagining the Tenth Dimension / Rob Bryanton</a></li>
</ul></li>
</ul>
</nav>
<p>All answers are by me (<a href="reddit.com/u/rantonels">u/rantonels</a>), unless specified otherwise.</p>
<h2 id="KGP">Kinematics/General Physics</h2>
<h3 id="KGP1">KGP1 - Why is <span class="math">\(c\)</span>/<span class="math">\(\hbar\)</span>/<span class="math">\(k_B\)</span>/(other fundamental constant) the value it is? What would happen if it was different?</h3>
<p>Why is <span class="math">\(c\)</span> (the speed of light in a vacuum) exactly <span class="math">\(299 \, 792 \, 458 \; \mathrm{m} / \mathrm{s}\)</span>?</p>
<p>The metre and the second are arbitrary units that originally referred in their definition to natural phenomena that were relevant to the daily life of humans. A second would be <span class="math">\(1/86400\)</span> of a day, the period of rotation of the Earth. The metre is one ten-millionth of the distance between the equator and the North Pole.</p>
<p>As soon as the necessary physics was consolidated, these definitions were replaced with the modern ones:</p>
<ol style="list-style-type: decimal">
<li><p>The second is <span class="math">\(9\,192\,631\,770\)</span> times the period of the radiation emitted in a specific atomic transition of <span class="math">\({}^{133}Cs\)</span>.</p></li>
<li><p>The metre is the length travelled by light in vacuum in <span class="math">\(1/299 \, 792 \, 458\)</span> of a second.</p></li>
</ol>
<p>The first definition is still referring to a natural process, albeit much more exact than the rotation of the Earth. The bizzarre number involved is to make sure the new definition makes a modern second as similar as possible to the older second. Basically, the period of the transition radiation had been previously <em>measured</em> as being <span class="math">\(1/9192631770 \, \mathrm{s}\)</span> (in older seconds).</p>
<p>The second one rests on the first and simultaneously fixes the value of <span class="math">\(c\)</span>. The units are explicitly <em>designed</em> so that the value of <span class="math">\(c\)</span> is <span class="math">\(299\,792\,458\)</span>. This value is similar to the previous, measured value of <span class="math">\(c\)</span> in the older units.</p>
<p>Instead, the value of <span class="math">\(c\)</span> in the new system is defined, not measured.</p>
<p>This means we can actually make <span class="math">\(c\)</span> have any value we want by redefining the units. If we use lightyears and years for measuring lengths and times, we get</p>
<p><span class="math">\[ c = 1 \; \mathrm{ly}/\mathrm{y} \]</span></p>
<p>But here it seems like we're just playing around with units. We aren't apparently actually <em>changing the speed of light</em>. Here's a little gedankenexperiment about that.</p>
<p>Assume there was a Universe where the speed of light was twice ours:</p>
<p><span class="math">\[ c&#39; = 2 c \]</span></p>
<p>Since the speed of light enters basically every relativistic phenomenon and many things about light and electromagnetism, you can bet the dynamics in this primed Universe will be very different from those in our unprimed one. For example, it's very likely it won't develop human life, at least in the same way as it happened for us.</p>
<p>However.</p>
<p>Consider the following change of variables in the primed Universe:</p>
<p><span class="math">\[ x&#39; \rightarrow \tilde{x}&#39; = x&#39;/2, \quad t&#39; \rightarrow \tilde{t}&#39; = t&#39;\]</span></p>
<p>The tilded coordinates are just the normal coordinates, but with space stretched by a factor of 2. In these coordinates, the value of the speed of light is:</p>
<p><span class="math">\[ \tilde{c} = \left(\frac{\tilde{x}&#39;}{\tilde{t}&#39;} \right)_\text{computed for a light ray} = \frac{1}{2}\frac{x&#39;}{t&#39;} = \frac{1}{2} c&#39; = c \]</span></p>
<p>So we have to admit that, in the tilded coordinates, the speed of light is back to its original value in our Universe. In those coordinates, the primed Universe satisfies the same equations of motion as our own, and evolves identically. It has the same Big Bang, the same primordial nucleosynthesis, the same star formation, a Sun identical to ours, and an Earth and humans.</p>
<p>The humans are twice as tall as us, yes. But they don't know that. Since their Earth is twice as big, their metre (the tilded metre) is twice ours, and they measure their height to be normal in their tilded metres.</p>
<p>They finally measure the speed of light to be <span class="math">\(299\,792\,458\)</span> metres per second.</p>
<p>So, nothing would happen. This is the manifestation of how fundamentally meaningless the value of the speed of light is. Mainly because there is no independent other speed with which to compare it, as all speeds in physics ultimately depend on it.</p>
<p>All of the above applies to the following set of independent fundamental physical constants:</p>
<p><span class="math">\(c\)</span>, <span class="math">\(\hbar\)</span>, <span class="math">\(k_B\)</span>, <span class="math">\(\epsilon_0\)</span>, <span class="math">\(G\)</span></p>
<p>and all those auxiliary constants formed by products of powers of those above. The above set is a maximal set of independent constants and is the largest set of constant for which you can simultaneously impose a fixed value by redefining the units. If you fix less than all of these, you get freedom in your system of units. For example, setting</p>
<p><span class="math">\(c = \hbar = k_B = \epsilon_0 = 1\)</span></p>
<p>gives natural units (Lorentz-Heaviside variant), useful in high-energy physics. Since you omitted <span class="math">\(G\)</span>, you still have a single arbitrary unit to fix. You can use the metre, for example, and the rest of the units follow. The time unit is <span class="math">\(c\mathrm{m}\)</span>, the energy unit is <span class="math">\(\frac{c\hbar}{\mathrm{m}}\)</span> and so on.</p>
<p>Adding <span class="math">\(G=1\)</span> instead gives Planck units.</p>
<h2 id="CM">Classical Mechanics</h2>
<h3 id="CM1">CM1 - Why is my physics teacher so anal about centripetal vs centrifugal? Is the centrifugal force &quot;fictitious&quot;?</h3>
<p>This one is an <em>extremely heated</em> question, and this baffles me because it has no reason to be so. Still, be wary that whatever your opinion, people will invariably shout at you. With that said, let's start.</p>
<p>Let's consider an object in uniform circular motion. This means we are in an inertial reference frame (say, laboratory, or <span class="math">\(K\)</span>) and we force an object of mass <span class="math">\(m\)</span> to follow a circular trajectory of radius <span class="math">\(R\)</span> with constant speed <span class="math">\(v\)</span>. We are interested in finding the acceleration of the object.</p>
<p>Let me rapidly review how one could compute such an acceleration. I'm gonna do it very very quickly using trigonometry, but most textbooks take more time and calculate <span class="math">\(\vec a\)</span> using a mostly &quot;geometric&quot; approach coherent with Newtonian tradition, so refer to them if you want a simpler proof. Here I'm interested more in dealing with it and moving on to the interesting conceptual question. So, in coordinates, with <span class="math">\(xy\)</span> the plane of rotation and <span class="math">\(z\)</span> the axis of rotation:</p>
<p><span class="math">\[ \vec r = R \begin{pmatrix} \cos(\omega t) \\ \sin(\omega t) \\ 0 \end{pmatrix} \]</span></p>
<p>Where <span class="math">\(\omega := v/R\)</span> is the angular velocity. Then differentiating:</p>
<p><span class="math">\[ \vec v = \frac{d}{dt} \vec r = \omega R \begin{pmatrix} - \sin(\omega t) \\ \cos(\omega t) \\ 0 \end{pmatrix} \]</span></p>
<p>Note that the norm of <span class="math">\(\vec v\)</span> is <span class="math">\(\omega R = v\)</span> which justifies the definition of <span class="math">\(\omega\)</span>. And differentiating again:</p>
<p><span class="math">\[ \vec a = R \omega^2 \begin{pmatrix} -\cos(\omega t) \\ -\sin(\omega t) \\ 0 \end{pmatrix} = - \omega^2 \vec r \]</span></p>
<p>so we have a purely radial acceleration pointing <em>inwards</em>, so a centripetal acceleration.</p>
<p>Centripetal (not centripe<strong>d</strong>al) and centrifugal are both words created by Sir Isaac himself back in 1687, who wrote in Latin. The first part of the word comes from <em>centrum</em>, &quot;centre&quot; (itself from Greek <em>κέντρον</em> meaning &quot;sharp point&quot;). -petal is from <em>petō</em>, meaning to beg, to seek. -fugal is from <em>fugiō</em>, meaning to flee. They're pretty self-explanatory when presented this way.</p>
<p>So we have a centripetal acceleration and consequently, if Newton's second law is to be trusted, then</p>
<p><span class="math">\[ \vec F = m \vec a\]</span></p>
<p>there must be a centripetal force. So to keep an object in circular uniform motion, a centripetal force pulling it towards the centre is necessary.</p>
<p>In fact, to keep the mass in circular motion we've needed exactly a force pushing <em>radially inwards</em>. If we use a rope, the tension of the rope is the centripetal force that keeps the mass in circular motion.</p>
<p>So far, no trace of the centrifugal force, and that's ok.</p>
<p>But now, let's move to the corotating frame <span class="math">\(K&#39;\)</span>. The corotating frame rotates along with the mass and the rope; in this frame the mass and rope are immobile, and the rest of the lab rotates around them. The position of the mass is fixed at:</p>
<p><span class="math">\[ \vec r&#39; = R \begin{pmatrix} 1 \\ 0 \\ 0 \end{pmatrix} \]</span></p>
<p>and the velocity <span class="math">\(\vec v&#39; = \frac{d}{dt} r&#39; = 0\)</span> and <span class="math">\(\vec a&#39; = 0\)</span>. So, if Newton's law held, we would have</p>
<p><span class="math">\[\vec F&#39; = 0\]</span></p>
<p>but we already knew the only force acting on the mass in the centripetal tension of the rope, which is definitely nonzero, so this makes very little sense.</p>
<p>The point is that the corotating frame is non inertial. An inertial frame is one where Newton's second law is true. Instead in a noninertial frame the difference between the forces applied and those needed for mantaining that motion is nonzero:</p>
<p><span class="math">\[m \vec a&#39; - \vec F&#39; =: \vec F_\text{in}\]</span></p>
<p><span class="math">\(F_\text{in}\)</span> are the so-called <em>inertial forces</em>, since they might as well be thought to be forces acting exclusively because we've moved to a non-inertial frame. The advantage of seeing these as forces is that we can restore Newton's second law by adding them together with the &quot;physical&quot; forces:</p>
<p><span class="math">\[ (\vec F&#39; + \vec F_\text{in} ) = m \vec a&#39; \]</span></p>
<p>which is pretty remarkable. In our case, <span class="math">\(\vec a&#39; = 0\)</span>, so</p>
<p><span class="math">\[\vec F_\text{in} = - \vec F_\text{tension}\]</span></p>
<p>so the inertial force points radially outwards, and is therefore a <em>centrifugal</em> force.</p>
<p>Why do, mathematically, inertial forces arise?</p>
<p>Consider a change of coordinates on space from frame <span class="math">\(K\)</span> to the corotating frame <span class="math">\(K&#39;\)</span>. This is in general given by a function <span class="math">\(\vec r&#39; = \xi(\vec r;t)\)</span>, where I've explicitated that our change of coordinates might depend on time. Now one typically in Newtonian mechanics works with <em>affine</em> coordinate changes, of the form:</p>
<p><span class="math">\[\vec r&#39; = \Omega(t) \vec r + \vec b(t)\]</span></p>
<p>where <span class="math">\(\Omega(t)\)</span> is a matrix and both <span class="math">\(\Omega(t)\)</span> and <span class="math">\(\vec b(t)\)</span> depend on time. The acceleration in <span class="math">\(K&#39;\)</span> is therefore</p>
<p><span class="math">\[v&#39; = \dot {\vec r} = \dot {\Omega} \vec r + \Omega \dot {\vec r} + \dot {\vec b}\]</span></p>
<p><span class="math">\[a&#39; = \dot{\vec v} = \ddot {\Omega} \vec r + 2 \dot {\Omega} \vec v + \Omega \vec a + \ddot {\vec b}\]</span></p>
<p>where I've made use of Newton's own dot notation for time derivatives. Note that <em>if</em> <span class="math">\(\Omega\)</span> and <span class="math">\(\vec b\)</span> were <em>constant</em> in time, we would have</p>
<p><span class="math">\[\vec v&#39;_0 = \Omega \vec v\]</span> <span class="math">\[\vec a&#39;_0 = \Omega \vec a\]</span></p>
<p>which is interesting. It means, for example, that if you change between frames of reference that are rotated between eachother by a constant angle (i.e.: <span class="math">\(\Omega\)</span> is a constant rotation matrix) then your new <span class="math">\(v\)</span> and <span class="math">\(a\)</span> will be the the old ones rotated by the same angle. Instead, in the general case where <span class="math">\(\Omega(t)\)</span> and <span class="math">\(\vec b(t)\)</span> are time-dependent, we get</p>
<p><span class="math">\[\vec a&#39; = \vec a&#39;_0 + \ddot{\Omega} \vec r + 2 \dot {\Omega} \vec v + \ddot{\vec b}\]</span></p>
<p>That is: the fact that the parameters that describe the change of coordinates in space depend on time <em>implies</em> that accelerations will be augmented by additional, &quot;spurious&quot; terms due to the variation in time of said parameters. We switch to forces by multiplying by <span class="math">\(m\)</span>:</p>
<p><span class="math">\[m \vec a&#39; = \vec F&#39; + m \left( \ddot {\Omega} \vec r + 2 \dot{ \Omega} \vec v + \ddot {\vec b}\right)\]</span></p>
<p><span class="math">\[=: \vec F&#39; + \vec F_\text{in}\left(\vec r&#39;,\vec v&#39;\right)\]</span></p>
<p>So, I've identified <span class="math">\(m \vec a&#39;_0\)</span> as the total &quot;physical&quot; force, that is the transformed version (<span class="math">\(\vec F&#39; = \Omega \vec F\)</span>) of the forces already present in <span class="math">\(K\)</span> (such as the centripetal force). But in addition to that we have all those other terms, which I've grouped together in the total inertial force <span class="math">\(\vec F_\text{in}\)</span>. I've written the inertial force as a function of the new position and velocity <span class="math">\(\vec r&#39;\)</span> and <span class="math">\(\vec v&#39;\)</span>, when the expressions above are in terms of <span class="math">\(\vec r\)</span> and <span class="math">\(\vec v\)</span>, but notice that it's easy to invert the <span class="math">\(\vec r&#39;(\vec r)\)</span> and <span class="math">\(\vec v&#39;(\vec v)\)</span> relationships and get <span class="math">\(\vec r(\vec r&#39;)\)</span> and <span class="math">\(\vec v(\vec v&#39;)\)</span>.</p>
<p>So Newton's law does not hold with <span class="math">\(\vec F&#39;\)</span> as the total force. But we have no theorem that says that <span class="math">\(\vec F&#39;\)</span> should be identified as the total force. So we have two entirely equivalent possibilities:</p>
<ul>
<li>Newton's law does not hold in non-inertial frames. <span class="math">\(\vec F&#39;\)</span> are definitely the forces acting in <span class="math">\(K&#39;\)</span>, while <span class="math">\(\vec F_\text{in}\)</span> are an artefact of the non-inertiality. Therefore they are &quot;fictitious&quot; forces.</li>
<li>Newton's law <em>does</em> continue to hold in non-inertial frames, but forces do not transform trivially between frames (i.e.: <span class="math">\(\vec F&#39; \neq \Omega \vec F\)</span>). In particular, when switching to non-inertial frames, multiple additional terms appear. The total force acting on <span class="math">\(K&#39;\)</span> then is the sum of the naive transform of the original force plus inertial forces. So inertial forces are absolutely real effects.</li>
</ul>
<p>Now, to the point where we've gotten so far, both seem absolutely equivalent viewpoints in terms of physics (which is just concerned about measurement results) and the question seem exquisitely philosophical. In light of this, why do people spend so much energy striving to prove the inherent superiority of the first version, the &quot;fictitious&quot; one? I'm talking about adages like</p>
<blockquote>
<p>inertial forces are fake forces, they are &quot;an illusion&quot;</p>
</blockquote>
<p>or even this</p>
<blockquote>
<p>&quot;centrifugal&quot; force? Maybe you mean <em>centripetal</em>. The centrifugal force does not exist.</p>
</blockquote>
<p>as if the centrifugal force suddenly became taboo. The answer is I don't know: I don't know why people do this. Wikipedia's article is literally named Fictitious Force, and this view was also very likely that of Newton.</p>
<p>Inertial forces are actually pretty real. If I'm riding a merry-go-round, I can measure a force pushing me outwards. If I weigh myself at the equator, I weigh slightly less than at the poles (assuming a spherical uniform Earth). Sure, you can just impose that non-inertial frames are fundamentally inferior to inertial frames and that the correct description of my dynamometer or scale is only that where it's rotating, but it's kind of annoying to call (even indirectly) the most complicated picture the &quot;more correct&quot; one. Still, the question mantains a purely philosophical nature and therefore I don't enjoy speculating on it.</p>
<p>Here's a pre-packaged answer if your professor asks you wheter a centrifugal or centripetal force is acting on a rotating object (which is an absolutely legitimate question to be anal about):</p>
<p>In the inertial frame of the lab, where the object performs the uniform circular motion, there is a centripetal force. In the corotating frame, there is both a centrifugal and centripetal force.</p>
<p>and if he asks &quot;yeah, well, ok, but which one is the <em>real</em> one&quot; then ask him to sod off and inform him that forces, like many things in life, depend on the reference frame. End of story.</p>
<p>A last thing: there is actually an immensely remarkable fact about the Universe that is a strong point in favour of the second view, that in which inertial forces are &quot;real&quot;:</p>
<p><strong>All four fundamental forces (electromagnetism, weak, strong, gravity) are inertial forces.</strong></p>
<p>For example, gravity can (by virtue of the equivalence principle and general relativity) be cancelled locally by a suitable change of coordinates. If you are standing on the surface of the Earth, a local change to free-falling coordinates cancels the gravitational force; it's instead the ground that is accelerating upwards at <span class="math">\(g\)</span> and pushing on you, accelerating you upwards. A free-falling object, instead, feels no force in this (local) frame. The sacred &quot;lab frame&quot; where stuff falls at <span class="math">\(g\)</span> is actually <em>non-inertial</em>, and the force of gravity is the inertial force associated with the non-inertiality of that frame! This is the fundamental starting point of general relativity. And in general relativity, sometime spacetime is curved, and <em>inertial frames do not exist</em>. A worldview obsessed with separating the &quot;real&quot; forces from the &quot;fake&quot; forces is in some serious difficulty.</p>
<p>But what's even more interesting (and less known) is that the other fundamental forces (electroweak and strong) act in a similar fashion. They are &quot;inertial&quot; forces due to the &quot;non-inertiality&quot; of some &quot;frame&quot; and can be locally cancelled by a suitable local &quot;change of coordinates&quot;. I put stuff in quotes because this actually involves coordinate transformations in some &quot;internal&quot; space instead of spacetime, but the math (gauge theory) is almost identical.</p>
<p>Note that the electromagnetic force is at the base of the microscopical description of the tension force holding the mass in circular motion, the centripetal force. So, no pun intended, we've come full circle.</p>
<h2 id="TD">Thermodynamics</h2>
<h2 id="OM">Celestial/Orbital Mechanics</h2>
<h2 id="FM">Fluid Mechanics</h2>
<h2 id="CED">Classical Electrodynamics</h2>
<h3 id="CED1">CED1 - What is the Maxwell stress tensor <span class="math">\(\mathbf{\sigma}\)</span> and how does it work?</h3>
<p><em>note: do not confuse this with the Maxwell tensor <span class="math">\(F^{\mu\nu}\)</span>, which is the electromagnetic field.</em></p>
<p>Consider linear momentum:</p>
<p><span class="math">\[ P^i \]</span></p>
<p>it's the i component of the total linear momentum in the system. It will be an integral over space of some linear momentum density I'll call <span class="math">\(p^i \)</span>:</p>
<p><span class="math">\[ P^i = \int d^3 x \; p^i(x) \]</span></p>
<p>This quantity is conserved. It's also pretty reasonable that it's somewhat conserved <em>locally</em>, meaning that it doesn't just disappear somewhere and reappear magically somewhere else, it has to <em>flow</em>.</p>
<p>What I mean is that if the amount of linear momentum in a certain region of space changes, it must be because of some flux in/out the surface of that region:</p>
<p><span class="math">\[ \frac{d}{dt} P_V^i = \int_V d^3 x \frac{d}{d t} p^i(x) = - \oint_{\partial V} d^2 \vec \Sigma \; \cdot \vec \Phi^i \]</span></p>
<p>I just wrote that the variation of <span class="math">\(P_V^i \)</span> (<span class="math">\(P^i\)</span> restricted to the volume V), which is equal to the integral of the variation of the density, must be counterbalanced by some flux <span class="math">\(\vec\Phi \)</span> that crosses the boundary <span class="math">\(\partial V \)</span>. If it's decreasing, then it must be leaking.</p>
<p>Now here's the thing: the stress tensor element <span class="math">\(\sigma_{ij} \)</span> is precisely the <em>flux of <span class="math">\(P^i\)</span> in the j direction</em>. It's how much <span class="math">\(P^i \)</span> is flowing through a unit surface orthogonal to the <span class="math">\(j\)</span>-direction. It is also symmetric (nontrivial, and in fact dependent on some choices) and it does transform like a 2-tensor, a matrix, which justifies the name.</p>
<p>So let's rewrite what we had:</p>
<p><span class="math">\[ \int_V d^3 x \frac{d}{dt} p^i = - \oint_{\partial V} d^2 \Sigma^j \; \sigma^{ij} \]</span></p>
<p>What I've done is:</p>
<ul>
<li>Rewritten the scalar product <span class="math">\(\vec \Sigma \cdot \vec \Phi^i \)</span> using indices as <span class="math">\(\Sigma^j \Phi^{ij} \)</span>. Be careful about these indices: i means which component of the momentum we're talking about, j is the vector index of the flux itself (which is a vector).</li>
<li>Recognized that <span class="math">\(\Phi^{ij} = \sigma^{ij} \)</span> from what we said earlier.</li>
</ul>
<p>Now what you would like to do is to deduce a differential, infinitesimal form of the equation above (which is known as the integral continuity equation). You do this by integrating over a very small cube; I'll spare you the details, but it's an easy computation, and you end up with:</p>
<p><span class="math">\[ \frac{\partial p^i}{\partial t} + \partial_j \sigma^{ij} = 0\]</span></p>
<p>or, in vector form:</p>
<p><span class="math">\[ \frac{\partial \vec p}{\partial t} + \vec \nabla \cdot \sigma = 0 \]</span></p>
<p>this is the continuity equation or local conservation (in differential form). (note that the density <span class="math">\(\vec p \)</span> is a vector, because it's the density of the vector <span class="math">\(\vec P \)</span>.)</p>
<p>In an interacting theory of electromagnetic fields and matter, both contribute to total linear momentum. So, reasonably, both will have a stress tensor:</p>
<p><span class="math">\[ \sigma^{ij} = \sigma^{ij}_{f} + \sigma^{ij}_{m} \]</span></p>
<p>and they will <strong>not</strong> be separately conserved. Only their sum, total stress, obeys the continuity equation we just found. The physical interpretation is that momentum can be exchanged between fields and matter. When an electron produces radiation, for example, that radiation carries away momentum from the electron. We can substitute the decomposition in the continuity equation to obtain:</p>
<p><span class="math">\[ \frac{\partial \vec p_f}{\partial t} + \vec \nabla \cdot \sigma_f = - \frac{\partial \vec p_m}{\partial t} + \vec \nabla \cdot \sigma_m =: \vec s \]</span></p>
<p>Where I have defined the source term <span class="math">\(s\)</span>.</p>
<p>This source term encapsulate the passage of momentum from charged matter to fields. So field momentum is not conserved separately, and s represents &quot;generation&quot; of momentum from charges. Fittingly, the equation is now called a continuity equation with sources.</p>
<p>So the Maxwell stress tensor is just <span class="math">\(\sigma_f \)</span>, the stress tensor for only the electromagnetic field.</p>
<p>What I've detailed up to now is the physical interpretation in general of the stress tensor in any local theory; classical EM is just the first field theory one usually encounters. The actual form of the tensor for electromagnetism in terms of <span class="math">\(E\)</span> &amp; <span class="math">\(B\)</span> is computed from the Poynting vector and a full derivation is presented in any decent CED textbook.</p>
<h3 id="CED2">CED2 - Why is current produced to a wire when moving a magnet close to it?</h3>
<p><em>this answer provided by <a href="https://www.reddit.com/user/Aliudnomen">/u/Aliudnomen</a></em></p>
<p>charged particles moving in a magnetic field experience a force called the Lorentz force, given by</p>
<p><span class="math">\[\vec{F}_L = q(\vec v \times \vec B)\]</span></p>
<p>With <span class="math">\(q\)</span> the charge of the particle. The cross product means that the force is perpendicular to both the velocity (<span class="math">\(\vec v\)</span>) and the magnetic field lines (<span class="math">\(\vec B\)</span>).</p>
<p>When you move the magnet close to the wire, you're essentially creating <a href="https://tap.iop.org/fields/electromagnetism/414/img_full_46963.gif">this situation</a>, only in this case it's the magnetic field that is 'moving' (actually changing). The movement of the bar PQ in the linked image causes a force on the charged particles inside it, from the right hand rule this force acts from P to Q for positively charged particles and from Q to P for negative ones.</p>
<p>If we go a little deeper, we find that we can express the force per unit charge as</p>
<p><span class="math">\[f = \vec{v} \times \vec{B}\]</span></p>
<p>Taking the line integral of this gives us the electromotive force that the magnetic field exerts on the charges in the wire:</p>
<p><span class="math">\[\text{emf} = \int_\text{wire} \vec{f} \cdot d\vec{r}\]</span></p>
<p>This electromotive force acts as a voltage, so you end up getting a current through your wire! The above is nicely summarized in Faraday's Law of Induction, one of Maxwell's famous equations:</p>
<p><span class="math">\(\nabla \times E = -\frac{\partial B}{\partial t}\)</span></p>
<p>Read: a changing magnetic field (such as when you move a magnet near a wire) induces an electric field.</p>
<h2 id="AM">Analytical Mechanics</h2>
<h3 id="AM1">AM1 - Why are <span class="math">\(q(t)\)</span> and <span class="math">\(\dot q(t)\)</span> treated as indipendent in Lagrangian mechanics? Shouldn't <span class="math">\(\dot q(t)\)</span> be viewed as a function(al) of <span class="math">\(q(t)\)</span>?</h3>
<p><em>this answer provided by <a href="https://www.reddit.com/user/Josef--K">u/Josef--K</a></em></p>
<p>For simplicity consider systems of one degree of freedom. Without further specification, all we know is that in general the Lagrangian is a function <span class="math">\[L:\mathbb{R}^3 \rightarrow \mathbb{R}; \;(q,v,t)\mapsto L(q,v,t) \]</span> As you see, no restrictions are placed on the domain here. The Lagrangian is a multivariable function, where position,velocity and time are .</p>
<p>We continue by defining the action <span class="math">\[S=\int_C L(q,v,t) \,ds\]</span> as a line integral over some path <span class="math">\(C\)</span> through the domain. In general such a path can be parametrized in function of one of the variables, time in this case, as <span class="math">\((q(t),v(t),t)\)</span>. The more familiar form of the action appears <span class="math">\[S=\int_{t_1}^{t_2} L(q(t),v(t),t) \,dt\]</span> From this moment on the position and velocity are considered  coordinates in the context of the action and are just explicit functions of time. The relationship between position and velocity as <span class="math">\(v=\dot{q}\)</span> has still not been used though.</p>
<p>We are going to assume that for a motion from <span class="math">\(q_1\)</span> to <span class="math">\(q_2\)</span> the parametrizations <span class="math">\((q(t),v(t),t)\)</span> that correspond to reality, are given by the paths that result in an extremum in the action <span class="math">\(S\)</span>. To find this minimum we are going to allow for variations in the position <span class="math">\(\delta q(t) \)</span> and in variations of velocity <span class="math">\(\delta v(t)\)</span>. It is only now that we remember the velocity being the position's time derivative and place the following restriction on the variations in the velocity <span class="math">\[\delta v(t)=\frac{d \delta q(t)}{dt}\]</span> What follows is a textbook derivation without many subtleties which results in: <span class="math">\[\frac{d}{dt} \frac{\partial{L(q,v,t)}}{\partial v}(q(t),\dot{q}(t),t) = \frac{\partial L(q,v,t)}{\partial q}(q(t),\dot{q}(t),t)\]</span></p>
<p>What is happening in this equation? The first thing that happens is the Lagrangian being treated as a multivariable function where the variables are independent. The partial derivatives of this function are taken on both sides and only then the parametrization <span class="math">\((q(t),v(t),t)\)</span> that minimizes the action is considered. This makes it possible to take a total time derivative of the left side which results in a differential equation for <span class="math">\(q(t)\)</span>.</p>
<p>To conclude we summarize that it is only the Lagrangian as a multivariable function that treats position and velocity as time independent. This is also the case for operators that work on the Lagrangian as a multivariable function, for example partial derivatives. In the derivation of the equations of motions, we assume that the variations in the velocities are given by the derivatives of the variations in the positions, which reflects the dependent treatment of the variables in this derivation.</p>
<h2 id="SR">Special Relativity</h2>
<h3 id="SR1">SR1 - In what sense does <span class="math">\(E=mc^2\)</span>, and what does it mean?</h3>
<p>Ok, ok, ok. Let's take a deep breath.</p>
<p>When switching from Newtonian to relativistic physics, a couple of formulas have to be explicitly replaced. In particular, we can summarize this shift in the following substitutions for the mechanical energy and linear momentum of a body:</p>
<p><span class="math">\[E_N = \frac{1}{2} m v^2 \longrightarrow E = \frac{1}{\sqrt{1-(v/c)^2}} m c^2\]</span></p>
<p><span class="math">\[p_N = m v \longrightarrow p = \frac{v/c}{\sqrt{1-(v/c)^2}} m c\]</span></p>
<p>These might look a bit daunting, and additionally I just pulled them out of my ass. Just trust me that they can be derived rigorously. Let us concentrate on interpreting them and their consequences.</p>
<p>The Newtonian expressions should be well-known; they are however incorrect when speed becomes relativistic (<span class="math">\((v/c) &gt; 0.1\)</span> is a good rule-of-thumb) and must be replaced by the formulas on the right.</p>
<p><span class="math">\(m\)</span> is the mass. Just mass. It's a constant <em>and</em> an invariant for the object. It does not depend on the frame of reference nor the <em>global</em> state of motion of the body (I'll clarify this adjective in a minute). Do not trust anyone talking about &quot;relativistic mass&quot;, it's an old concept from when people were still trying to figure out this stuff and it makes everything <em>immensely</em> more complex (just a taste: there is a transverse and a longitudinal relativistic mass). Only ever discuss invariant mass, or just mass.</p>
<p><span class="math">\(v\)</span> is simply how much space the body travels over how much time, with space and time measured in a certain inertial frame. I really want to stress the simplicity of this definition, because people often get confused with time dilation and length contraction and other complications, while this definition is absolutely crystal clear:</p>
<p><span class="math">\[ v = \frac{dx}{dt} \]</span></p>
<p>where <span class="math">\(x\)</span> and <span class="math">\(t\)</span> are the space and time coordinates of the body in some coordinate system (reference frame), nothing to do with proper time or anything of that sort. No magic here.</p>
<p>And <span class="math">\(c\)</span>, of course, is the speed of light in vacuum.</p>
<p>The <span class="math">\(v/c\)</span> ratio and the <span class="math">\((1-(v/c)^2)^{-1/2}\)</span> thing are so ubiquitous in SR that we give them the following names:</p>
<p><span class="math">\[ \beta := v/c \quad\quad\quad \gamma := \frac{1}{\sqrt{1-\beta^2}}\]</span></p>
<p>So the formulas simplify to <span class="math">\(E = \gamma m c^2\)</span> and <span class="math">\(p = \beta \gamma m c\)</span>.</p>
<p>Now, the burden of proving that the relativistic expressions do actually reduce to the Newtonian expressions in the nonrelativistic limit is on us. The nonrelativistic limit is when <span class="math">\(v \ll c\)</span>, or equivalently <span class="math">\(\beta \ll 1\)</span>. To do so, let us recall the following Taylor expansion from calculus:</p>
<p><span class="math">\[ (1+\epsilon)^\alpha = 1 + \alpha \epsilon + \frac{\alpha(\alpha-1)}{2!} \epsilon^2 + \ldots \]</span></p>
<p>this is simply the Binomial expansion and it's a really useful one to keep in mind (at least the first order term). We expand the <span class="math">\(\gamma\)</span> factor using <span class="math">\(\epsilon = -\beta^2\)</span> as such:</p>
<p><span class="math">\[ \gamma = \left(1-\beta^2 \right)^{-1/2} = 1 + \frac{1}{2} \beta^2 + \ldots \]</span></p>
<p>Second-order in <span class="math">\(\beta\)</span> is all we really need. So, finally, for the mechanical energy and momentum in the nonrelativistic limit we get:</p>
<p><span class="math">\[ E = m c^2 + \frac{1}{2} m v^2 + \ldots\]</span> <span class="math">\[ p = m v + \ldots\]</span></p>
<p>In the expression for <span class="math">\(p\)</span> I've stopped at the first term because the next is order <span class="math">\(\beta^3\)</span>.</p>
<p>There's something seriously wrong. <span class="math">\(p\)</span> looks like its Newtonian counterpart <span class="math">\(p_N\)</span>, while <span class="math">\(E\)</span> has an additional spurious term, <span class="math">\(mc^2\)</span>. This is not a small term. In fact it's huge.</p>
<p><span class="math">\(E_0 := mc^2\)</span> is the energy the body has when <span class="math">\(v=0\)</span>, so it's called the rest energy. Why does it not completely invalidate Newtonian mechanics?</p>
<p>Mostly, it's because it's impossible to tap into this energy. In nonrelativistic mechanics, mass is conserved (it is <strong>not</strong> conserved in special relativity). This means that in any physical process, <span class="math">\(E_0\)</span> is untouched. It decouples completely from the physics, and thus it's just an invisible energy shift.</p>
<p>Mechanics (and Physics in general) is insensible to global energy shifts. For example, if your mechanical energy is</p>
<p><span class="math">\[ E = \frac{1}{2} m v^2 + 49\, \text{J} \]</span></p>
<p>nothing changes in your dynamics. You just added a constant, so what. Since <span class="math">\(mc^2\)</span> is effectively a constant in nonrelativistic physics, it does not affect dynamics and could not be derived even in principle by a nonrelativist not aware of special relativity. In fact, Newton just set that constant to zero for simplicity.</p>
<p>Now, we said that <span class="math">\(E_0\)</span> is the energy the body has when it's at rest. So we can conveniently divide our total energy in <span class="math">\(E_0\)</span> and a term we rightfully call kinetic energy:</p>
<p><span class="math">\[ E = \gamma m c^2 = m c^2 + (\gamma - 1) m c^2 =: E_0 + E_K\]</span></p>
<p>Since <span class="math">\(\gamma-1 \sim \frac{1}{2} \beta^2\)</span> it's clear that the nonrelativistic limit is just <span class="math">\(E_K \ll E_0\)</span>.</p>
<p>This is starting to make sense: <span class="math">\(E_0\)</span> is the energy the object has simply for existing, there is an energy cost associated with just having a mass. It is the difference between the energy of a state where the object exists (and is still) and one where it doesn't. It's the required energy to create it, or the yield if it's destroyed. Of course, this does not prove that it's possible to create or destroy mass, just that <em>if</em> there is a channel for that creation or destruction, that is the energy requirement.</p>
<p>Since in nonrelativistic mechanics the energies involved in processes (<span class="math">\(E_K\)</span>) are much smaller than the <span class="math">\(E_0\)</span> for an object, creation and destruction of mass most certainly do not happen in nonrelativistic physics.</p>
<p>Since <span class="math">\(E_0\)</span> is the total energy of the object when it's still, it's reasonable that if the object was a composite system made of smaller units, it also includes the internal energy, not just the sum of the rest energies of the components.</p>
<p>Take for example a stationary box filled with a gas at temperature T. The overall, or average velocity of the gas is zero, but the single particle of the gas will have a nonzero velocity and consequently a kinetic energy <span class="math">\(E_K^i\)</span>. The total energy is</p>
<p><span class="math">\[\sum_i E^i = \sum_i m c^2 +  \sum_i E_K^i \]</span></p>
<p>but we have said that this must be <span class="math">\(E_0 = M c^2\)</span>, with <span class="math">\(M\)</span> the mass of the box, so</p>
<p><span class="math">\[ M = \sum_i m + \frac{1}{c^2} (\sum_i E_K^i) \]</span></p>
<p>So, the mass of the box is actually greater than the sum of the masses of the particles! Albeit, by a very, very small amount, that only gets relevant if <span class="math">\(E_K^i\)</span> is at least of order <span class="math">\(m c^2\)</span>. This shows that mass is not additive, and displays the so called &quot;mass-energy equivalence&quot; which is more correctly expressed as:</p>
<p><span class="math">\[U = m c^2\]</span></p>
<p>that is, mass (as in, the inertia measured in Newtonian mechanics) is equivalent to the <em>total</em> <strong>internal</strong> energy, also including the energy to create the constituents.</p>
<p>This is why people will shout at you that <span class="math">\(E=mc^2\)</span> is not the full formula/is wrong. They're right. That <span class="math">\(E\)</span> is supposed to be <span class="math">\(E_0\)</span>.</p>
<h3 id="SR2">SR2 - if photons are massless, how can <span class="math">\(E=mc^2\)</span>?</h3>
<p>Read <a href="#SR1">SR1</a>.</p>
<p>The formulas in SR1 are singular if <span class="math">\(v=c\)</span>, which is certainly the case for a photon, a quantum of light. We need to rewrite them by getting rid of the velocity. (Or take a careful limit. That's a nice alternative. But we won't do that).</p>
<p>In classical mechanics, this is already done when switching from the Lagrangian to the Hamiltonian. You want to write <span class="math">\(E(v)\)</span> in function of <span class="math">\(p(v)\)</span>. So you invert <span class="math">\(p(v)\)</span> as <span class="math">\(v(p)\)</span> and then substitute <span class="math">\(E(v(p))\)</span>. Easier done than said:</p>
<p><span class="math">\[ p_N = mv  \Rightarrow\]</span> <span class="math">\[ v = \frac{p_N}{m} \]</span> <span class="math">\[ E_N(v) = \frac{1}{2} m v^2 \Rightarrow E_N(p) = \frac{p_N^2}{2m} \]</span></p>
<p>Which you'll recognize as a standard kinetic Hamiltonian if you're into Hamiltonian mechanics and you'll ignore this sentence if you don't.</p>
<p>We can do the same with the relativistic case. But first, a neat fact about <span class="math">\(\beta\)</span> and <span class="math">\(\gamma\)</span>:</p>
<p><span class="math">\[\gamma^2 - (\beta \gamma)^2 = 1\]</span></p>
<p>try it. It's very boring, but it's true. (It's cool because it implies that if <span class="math">\(\gamma = \cosh(\eta)\)</span>, then <span class="math">\(\sinh(\eta) = \beta \gamma\)</span> and <span class="math">\(\tanh(\eta)=\beta\)</span> and if you don't think hyperbolic functions are the shit then I don't know what to tell you).</p>
<p>So, we write</p>
<p><span class="math">\[ \gamma = \sqrt{1+(\beta\gamma)^2} \]</span> <span class="math">\[ E = \gamma m c^2 = \sqrt{1+(\beta\gamma)^2} m c^2 \]</span> <span class="math">\[ =  \sqrt{ (mc^2)^2 + (\beta\gamma m c^2)^2} \]</span> <span class="math">\[ = \sqrt{ (mc^2)^2 + (pc)^2 } \]</span></p>
<p>So this is our <span class="math">\(E(p)\)</span>, the so-called &quot;full expression&quot; for the mechanical energy of a relativistic body.</p>
<p>(If you Taylor-expand <span class="math">\(E(p)\)</span> around <span class="math">\(p=0\)</span>, you get <span class="math">\(E = mc^2 + \frac{p^2}{2m} + \ldots\;\)</span>. Go figure.)</p>
<p>Ok, so we've gotten rid of the gammas and betas. Just a last thing about them! The speed of an object is always recoverable from the energy and momentum:</p>
<p><span class="math">\[\frac{p}{E} c^2 = \frac{\beta \gamma m c}{\gamma m c^2} c^2 = \beta c = v \]</span></p>
<p>And only now that we have built this architecture we plug in <span class="math">\(m=0\)</span> to find about massless particles. We get</p>
<p><span class="math">\[ E = pc \]</span></p>
<p>and</p>
<p><span class="math">\[ v = c, \quad \gamma = \infty\]</span></p>
<p>So massless particles move always at the speed of light and have energy proportional to their momentum. In the limit where the momentum goes to zero, <span class="math">\(p\rightarrow 0\)</span>, the energy also goes to zero. Instead, for massive objects the energy tends to the rest energy <span class="math">\(mc^2\)</span>. Therefore it makes sense to extend the definition of the rest energy <span class="math">\(E_0 = mc^2\)</span> to photons, with <span class="math">\(m=0\)</span>, even if the cannot ever be brought to rest.</p>
<p>The energy of a photon is entirely kinetical.</p>
<p>Note that the previous expressions <span class="math">\(E = \gamma(v) m c^2\)</span> and <span class="math">\(p = \beta(v)\gamma(v) m c\)</span> when <span class="math">\(m=0\)</span> are both indeterminate forms (<span class="math">\(0\cdot\infty\)</span>). This makes sense: we have many photons, all with <span class="math">\(v=c\)</span>, with different momentum and energy. We shouldn't be able therefore to determine the energy/momentum exactly just from the speed, so the math honourably breaks down.</p>
<h2 id="GR">General Relativity</h2>
<h2 id="QM">Quantum Mechanics</h2>
<h2 id="QFT">General Quantum Field Theory/Many Body/Relativistic QM</h2>
<h2 id="NP">Nuclear Physics</h2>
<h2 id="QED">Quantum Electrodynamics</h2>
<h3 id="QED1">QED1 - How does <span class="math">\(1+2+3+\ldots=-1/12\)</span>/<span class="math">\(\zeta\)</span>-regularization enter in the Casimir effect?</h3>
<p>The Casimir effect is an attractive force between very close parallel conducting plates and it's a consequence of the quantum nature of the EM field. There are numerous ways to derive it, with various levels of rigour, but the one employing zeta-regularization holds a special place in my heart.</p>
<p>For simplicity, reduce from three to just one spatial dimension. This doesn't change the essential points of the computation. Then our parallel plates are actually two barriers, one at <span class="math">\(x=0\)</span> and one at <span class="math">\(x=a\)</span>, with <span class="math">\(a\)</span> the spacing. We know conductors act in a way as to make the longitudinal component of the electric field vanish on them. So we can model these boundary conditions as</p>
<p><span class="math">\[ \vec E(t,0) = 0 \quad \quad \vec E(t,a) = 0\]</span></p>
<p>The electric field satisfies the wave equation both inbetween and outside the plates:</p>
<p><span class="math">\[ \Box \vec E(t,x) = \left( \frac{1}{c^2} \partial_t^2 - \partial_x^2 \right) \vec E(t,x) = 0 \]</span></p>
<p>Now, since this equation is linear it's really tempting to write down a Fourier series for the electric field. We know that any function on the interval <span class="math">\([0,a]\)</span> can be expanded in this basis of fundamental waves:</p>
<p><span class="math">\[ S_n(x) = \sin(k_n x)\]</span></p>
<p>with <span class="math">\(k=\frac{\pi n}{a}\)</span>, <span class="math">\(n=1,2,\ldots\)</span>. These are a bit different than the usual presentation of Fourier Series in that they use only sines (but halve the lowest period). If you are not familiar with Fourier sine series <a href="http://web.mit.edu/18.06/www/Spring09/sines.pdf">this</a> is a good read.</p>
<p>We can decompose any function on the interval in this basis:</p>
<p><span class="math">\[ f(x) = \sum_{n=1}^\infty f_n \sin(k_n x) \]</span></p>
<p>So let's do that for the electric field at a given time <span class="math">\(t\)</span>.</p>
<p><span class="math">\[ \vec E(t,x) = \sum_{n=-\infty}^\infty \sum_i A_{ni}(t) \sin(k_n x) \vec e_i \]</span></p>
<p>Since <span class="math">\(\vec E\)</span> is a vector, we have to introduce two basis polarization vectors <span class="math">\(\vec e_y\)</span>, <span class="math">\(\vec e_z\)</span> pointing in the <span class="math">\(y\)</span> and <span class="math">\(z\)</span> directions, and sum over polarization (<span class="math">\(i=y,z\)</span>). We have therefore two modes of oscillation for each value of <span class="math">\(n\)</span>, corresponding to the two polarizations. The <span class="math">\(\vec e_x\)</span> polarization does not exist, because the electromagnetic field does not have a longitudinal component in free space.</p>
<p><span class="math">\(A_{ni}(t)\)</span> is the coefficient of the expansion of <span class="math">\(\vec E(t)\)</span> in the mode given by <span class="math">\(n\)</span> and <span class="math">\(i\)</span>, and obviously depends on time.</p>
<p>The expression obtained for the electric field automatically satisfies the boundary conditions <em>if</em> the coefficient <span class="math">\(A_{ni}\)</span> are not too crazy (it's still an infinite sum of functions, it's no joke).</p>
<p>Let us study the time evolution of <span class="math">\(A_{ni}\)</span>. Since the equation is linear, we just plug into the equation one single term from our expansion of the electric field:</p>
<p><span class="math">\[ \Box ( A_{ni}(t) \sin(k_n x) ) = \frac{1}{c^2} \left(\partial_t^2 A_{ni}(t) \right) \sin(k_n x) - k_n^2 A_{ni}(t) \sin(k_n x) = 0 \Rightarrow \]</span></p>
<p><span class="math">\[ \partial_t^2 A_{ni}(t) + \omega_n^2 A_{ni}(t) = 0 \]</span></p>
<p>with <span class="math">\(\omega_n = ck_n\)</span>. This is the equation for a harmonic oscillator! Of course this is no surprise, it's well-known that</p>
<p><span class="math">\[ \vec E_{ni} (t,x) = A_{ni} (t) \sin(k_n x) \vec e_i\]</span></p>
<p>is a standing-wave solution for the wave equation. The interesting bit is that this can be a way to get insight about the quantization without actually studying quantum field theory. This is because anyone who has studied a bit of basic quantum mechanics knows about the quantum harmonic oscillator (QHO) and how it's energy spectrum is given by</p>
<p><span class="math">\[ \mathcal{E} = \hbar \omega \left(m + \frac{1}{2}\right) \quad \quad m = 0,1,2,\ldots \]</span></p>
<p>So we hope that substituting our classical harmonic oscillator with its quantum counterpart we would be doing something presumably similar to what actually quantizing the EM field is. Let's try that. Each mode <span class="math">\((n,i)\)</span> has a QHO associated with energy</p>
<p><span class="math">\[\mathcal{E}^{ni} = \hbar \omega_n \left( m^{ni} + \frac{1}{2} \right) \]</span></p>
<p>and the total energy of the quantum EM field is given by <span class="math">\(\mathcal{E} = \sum_n \sum_i \mathcal{E}^{ni}\)</span>.</p>
<p>We have unknowingly discovered photons.</p>
<p>The number <span class="math">\(m^{ni}\)</span> is actually <em>the number of photons in the mode <span class="math">\((n,i)\)</span></em>, and takes the name of occupation number. Since photons are indistinguishable, you can describe the total state just by specifying how many photons have momentum <span class="math">\(\hbar k\)</span> and polarization <span class="math">\(\vec\varepsilon\)</span>, how many <span class="math">\(\hbar k&#39;\)</span> and <span class="math">\(\vec\varepsilon&#39;\)</span>, and so on; so just the full set of occupation numbers. The state with lowest energy possible is the one with <span class="math">\(0\)</span> photons in each single mode, and we call that the vacuum. All the <span class="math">\(m^{ni}\)</span> vanish and we are left with the energy per mode:</p>
<p><span class="math">\[\mathcal{E}_0^{ni} = \frac{ \hbar \omega_n}{2}\]</span></p>
<p>this is called the zero-point energy of the QHO, and is well-known to students of quantum mechanics. Even with zero photons in a specific mode, that mode has a certain energy. We can write down the total energy of the vacuum as the sum of the zero-point energies over all modes:</p>
<p><span class="math">\[\mathcal{E}_0 = \sum_{n=1}^\infty \sum_i \frac{\hbar \omega_n}{2} = \frac{\hbar c \pi}{a} \sum_{n=1}^\infty n = \frac{\hbar c \pi}{a} \left(1+2+3+4+\ldots \right) = \infty \]</span></p>
<p>Ugh. It's divergent. The total vacuum energy inbetween the plates is infinite. Physically, we can interpret it as being due to the ever-increasing contribution of high-momentum modes (it's a &quot;UV&quot; thing in QFT-speak). This divergence is most annoying and we must get rid of it someway. The reason I'm making you compute the total vacuum energy is more or less this: if the vacuum energy depends on the value of the separation <span class="math">\(a\)</span>, then it acts as a sort of potential energy, that induces a force on the plates. I mean</p>
<p><span class="math">\[ U(a) = \mathcal{E}_0(a) \Rightarrow F(a) = - \frac{d}{da} U(a) \]</span></p>
<p>but if <span class="math">\(U(a)\)</span> is infinity that's kind of difficult to work with. There must be another infinity we should subtract to cancel the divergence. An interesting candidate is the <em>vacuum energy in the region without the plates if the plates were not there</em>. We can subtract that:</p>
<p><span class="math">\[ U(a) = \mathcal{E}_0(a) - \mathcal{E}_0^{\text{no plates}} \]</span></p>
<p>Makes sense, <span class="math">\(U(a)\)</span> it's the energy associated with putting the plates there. Now <span class="math">\(\mathcal{E}_0^{\text{no plates}}\)</span> is computed in a way entirely analogous to how we calculated <span class="math">\(\mathcal{E}_0(a)\)</span>, but with a significant difference: the wavenumber <span class="math">\(k\)</span> is a continuous variable. Inbetween the plates the electric field was constrained by the boundary conditions and therefore only multiples of the fundamental wavenumber <span class="math">\(k_1 = \frac{ \pi n}{a}\)</span> were allowed. No such restriction exists without them and long story short our potential ends up being the difference of a divergent sum and a divergent integral:</p>
<p><span class="math">\[ U(a) = \frac{\hbar c \pi}{a} \left( \sum_{n=1}^\infty n   -  \int_0^\infty n dn \right) = \infty - \infty\]</span></p>
<p>That's looking undoubtedly better, but it's still bad. We are still summing and integrating to infinity <em>separately</em>, then subtracting. Let's instead trying summing/integrating <em>simultaneously</em>, and see if something cancels before we go to infinity. For this we introduce a regulator <span class="math">\(\Lambda\)</span>, a maximum value for <span class="math">\(n\)</span>. Then we hope to find that in the limit <span class="math">\(\Lambda\rightarrow \infty\)</span> we get a finite result not depending on <span class="math">\(\Lambda\)</span>. This is also physically reasonable: the conductor blocks the electric field by having electrons oscillate with the same frequency in a way to cancel out the field of an incoming wave; above a certain frequency, we expect the conductor to not be able to catch up. The conductor <em>must</em> be permeable to EM waves above some frequency. Anyways, so we do</p>
<p><span class="math">\[ U(a) = \frac{\hbar c \pi}{a} \left( \sum_{n=1}^\Lambda n - \int_0^{\Lambda} n dn \right)\]</span></p>
<p>Which is better, because the sum of the first <span class="math">\(\Lambda\)</span> integers goes as <span class="math">\(\sim \frac{1}{2} \Lambda^2\)</span> and the integral from <span class="math">\(0\)</span> to <span class="math">\(\Lambda\)</span> goes as <span class="math">\(\sim\frac{1}{2} \Lambda^2\)</span>, so the leading contributions cancel! This does not prove that the difference then is finite as <span class="math">\(\Lambda \rightarrow \infty\)</span>, but it's a good start. There is an explicit formula for calculating this kind of divergent series minus divergent integral things and it's the Euler-MacLaurin formula, but it's really convoluted computationally. I just want to say that what we would get it's exactly the result if we had, naively, made the substitution</p>
<p><span class="math">\[ 1+2+3+\ldots \rightarrow -\frac{1}{12} \]</span></p>
<p>which is what is dictated by <span class="math">\(\zeta\)</span>-regularisation. This is, very handwavingly, because <span class="math">\(\zeta\)</span>-regularisation makes some kind of statement that could be depicted schematically as:</p>
<p><span class="math">\[ 1+2+3+\ldots = \infty - \frac{1}{12}\]</span></p>
<p>and we then subtract exactly that infinity when removing <span class="math">\(\mathcal{E}_0^{\text{no plates}}\)</span>. Now, this is not a rigorous statement, but it's undoubtedly much easier to compute this way, and we immediately get our result:</p>
<p><span class="math">\[ U(a) = \frac{\hbar c \pi}{a} \frac{-1}{12} = - \frac{\hbar c \pi}{12 a} \]</span> <span class="math">\[ \Rightarrow F(a) = -\frac{d}{da} U(a) = - \frac{\hbar c \pi}{12 a^2} \]</span></p>
<p>That's cool, and it's attractive, but that's not the expression for the Casimir force on Wikipedia. Remember we've done this in one dimension; in three dimensions you get</p>
<p><span class="math">\[ \frac{U(a)}{A} = - \frac{\pi^2}{720} \frac{\hbar c}{a^3} \]</span> <span class="math">\[ \Rightarrow \frac{F(a)}{A} = - \frac{\pi^2}{240} \frac{\hbar c}{a^4}\]</span></p>
<p>which is the well-known expression - everything is per unit of area of the plates. (In this case, the divergent sum-integral pair is not the same as <span class="math">\(1+2+3+\ldots\)</span>, but it's equally nasty, and the same arguments apply).</p>
<p>AFAIK the Casimir force with the expression above was experimentally observed in at least two great experiments, first by Lamoreaux in 1997 at the U of Washington and then by Bressi, Carugno, Onofrio, Ruoso in 2002 at the University of Padua. There is now an entire field of Casimir nanophysics.</p>
<p>Good reads:</p>
<ul>
<li>For more on the justification and meaning of the use of <span class="math">\(\zeta\)</span>-regularisation in the Casimir effect and vacuum energy: <a href="https://en.wikiversity.org/wiki/Quantum_mechanics/Casimir_effect_in_one_dimension">https://en.wikiversity.org/wiki/Quantum_mechanics/Casimir_effect_in_one_dimension</a></li>
<li>Terrence Tao on <span class="math">\(\zeta\)</span>-reg: <a href="https://terrytao.wordpress.com/2010/04/10/the-euler-maclaurin-formula-bernoulli-numbers-the-zeta-function-and-real-variable-analytic-continuation/">https://terrytao.wordpress.com/2010/04/10/the-euler-maclaurin-formula-bernoulli-numbers-the-zeta-function-and-real-variable-analytic-continuation/</a></li>
<li>For a concise derivation in three dimensions using <span class="math">\(\zeta\)</span>-reg: <a href="https://en.wikipedia.org/wiki/Casimir_effect#Derivation_of_Casimir_effect_assuming_zeta-regularization">https://en.wikipedia.org/wiki/Casimir_effect#Derivation_of_Casimir_effect_assuming_zeta-regularization</a></li>
<li>Some people are strongly critical or at least skeptic of vacuum fluctuations as the correct way to see the Casimir effect. A sensible argument is <a href="http://arxiv.org/abs/hep-th/0503158">http://arxiv.org/abs/hep-th/0503158</a></li>
</ul>
<h2 id="HEP">Particle Physics/High Energy Physics</h2>
<h3 id="HEP1">HEP1 - Why are photons massless?</h3>
<p>Photons, being gauge bosons of a gauge theory, are a priori massless. At least classically, a mass term for the photon in the Lagrangian:</p>
<p><span class="math">\[ \frac{m^2}{8\pi} A_\mu A^\mu\]</span></p>
<p>is not invariant under the gauge transformation</p>
<p><span class="math">\[ A_\mu \rightarrow A_\mu + \partial_\mu \Lambda \]</span></p>
<p>and thus gauge invariance disallows a photon mass. The massive photon Lagrangian one would instead obtain with the above term is the Proca theory of the massive vector boson.</p>
<p>However, photons could still in principle acquire a mass through at least a couple of mechanisms. The first is also present at the classical level and is the Higgs mechanism and variants, where gauge invariance is &quot;broken&quot;, in some careful sense (gauge symmetry breaking is more involved than global symmetry breaking). Why the photon is not affected by the Higgs mechanism is treated in <a href="#HEP2">HEP2</a>. The second happens upon quantization and is the quantum correction to the mass. Particles in general acquire quantum corrections to their physical parameters that can be investigated as being due with interaction with virtual particles as the original particle travels from point A to point B. The photon is again protected from this phenomenon and this is explained in <a href="#HEP3">HEP3</a>.</p>
<h3 id="HEP2">HEP2 - Why do photons not acquire a mass through the Higgs mechanism?</h3>
<p>By definition!</p>
<p>Photons are by definition the single component of the original <span class="math">\(SU(2)\times U(1)\)</span> electroweak gauge field that leaves the Higgs vacuum expectation value invariant. This means that the VEV is uncharged for the photon, and the photon aquires no mass.</p>
<p>A little simpler: basically, <span class="math">\(SU(2)\times U(1)\)</span> is a four dimensional group of transformation. The Higgs is a field which takes value in a four-dimensional (two-complex dimensional) vector space and which is transformed (&quot;rotated&quot;) by these transformations. Now after electroweak symmetry breaking the Higgs aquires a VEV, which just mean that in all of space it assumes the value of a specific vector in that 4-dimensional space. This vector is not invariant under the original gauge group, this means that it breaks the symmetry. There is however a 1-dimensional subgroup of the gauge group that still leaves the VEV invariant and thus that symmetry remains unbroken. That group's generator is defined to be the photon and the preserved gauge symmetry assures the photon has no mass. The other three generators instead do interact with the VEV and acquire mass. They are decomposed in three orthogonal generators by electric charge: <span class="math">\(W^+\)</span>, <span class="math">\(W^-\)</span>, <span class="math">\(Z^0\)</span>.</p>
<p>And now, more detailed: assume WLOG that the Higgs has VEV as such:</p>
<p><span class="math">\[ \phi = \begin{pmatrix} 0 \\ \phi_0 \end{pmatrix} \]</span></p>
<p>with <span class="math">\(\phi_0\)</span> real, and the generic gauge group element acts on <span class="math">\(\phi\)</span> as</p>
<p><span class="math">\[ \phi \rightarrow \exp\left(i \left(\frac{g&#39;}{2} B \cdot \mathbb{1} + g W_1 T^1 + g W_2 T^2 + g W_3 T^3\right) \right) \phi\]</span></p>
<p>Where <span class="math">\(B\)</span> and <span class="math">\(W_i\)</span> are respectively the gauge field for weak hypercharge (<span class="math">\(U(1)\)</span>) and weak isospin (<span class="math">\(SU(2)\)</span>), <span class="math">\(T^i= \frac{\sigma^i}{2}\)</span> are generators for <span class="math">\(SU(2)\)</span>, and <span class="math">\(g\)</span>, <span class="math">\(g&#39;\)</span> are the corresponding coupling constants.</p>
<p>We impose <span class="math">\(\phi&#39; = \phi\)</span> to find the little group of the VEV (the isotropy group). For infinitesimal generators, the above reduces to:</p>
<p><span class="math">\[ \begin{pmatrix} g&#39;B + g W_3 &amp;  g (W_1 + i W_2) \\ g (W_1 - i W_2) &amp; g&#39;B - g W_3 \end{pmatrix} \begin{pmatrix} 0 \\ \phi_0  \end{pmatrix} = 0 \]</span></p>
<p>This gives immediately <span class="math">\(W_1 = W_2 = 0\)</span> (as they are real generators) and <span class="math">\(g&#39;B - g W_3 = 0\)</span>; this means that the generator <span class="math">\(A = \frac{1}{\sqrt{g&#39;^2+g^2}} (g&#39; W_3 + g B)\)</span> solution to the latter two equations generates the one-dimensional isotropy group. This generator is the photon.</p>
<p>The other three generators do modify the value of the Higgs and are orthogonalized into the <span class="math">\(W^{\pm} = \frac{1}{\sqrt 2} (W_1 \pm i W_2) \)</span> and <span class="math">\(Z^0 =  \frac{1}{g^2+g&#39;^2} (g W_3 - g&#39; B) \)</span>.</p>
<p>The mass generation is evidenced by expanding the kinetic term of the Higgs Lagrangian around the VEV. This gives a mass term for the gauge boson which is precisely the norm squared of <span class="math">\(\left(\frac{g&#39;}{2} B \cdot \mathbb{1} + g W_i T^i \right) \begin{pmatrix}0\\ \phi_0 \end{pmatrix} \)</span>. Therefore the orthonormal states <span class="math">\(A\)</span>, <span class="math">\(W^{\pm}\)</span>, <span class="math">\(Z^0\)</span> above diagonalize the mass matrix, and <span class="math">\(A\)</span> is the single one with eigenvalue <span class="math">\(0\)</span>, as was shown before.</p>
<h3 id="HEP3">HEP3 - Why do photons not acquire a mass through quantum corrections/interaction with virtual particles? What is charge renormalization?</h3>
<p>The short answer is that quantum corrections to the photon propagator do not give it a mass because of the Ward identity, which is a consequence of gauge invariance.</p>
<p>The probability amplitude for a photon to go from point A to point B is given by what is called the propagator. The &quot;bare&quot; propagator is given by the following expression:</p>
<p><img src="images/bare.svg" title="bare" /> <span class="math">\(= \pi^{\mu\nu}(q) = \frac{-ig^{\mu\nu} }{q^2 + i\epsilon} \)</span></p>
<p>where <span class="math">\(q\)</span> is the four-momentum of the photon and <span class="math">\(\epsilon\)</span> is a funny thing you shouldn't worry about. In fact, put it to 0. This is how a massless propagator should look. The mass of the particle is given by where the propagator is singular (has a pole), so in this case <span class="math">\(q^2 = m^2 = 0\)</span>. (If the photon was massive, in the denominator we would have <span class="math">\(q^2-m_\gamma^2 + i \epsilon\)</span>). The propagator has two Lorentz indices <span class="math">\(\mu\)</span> and <span class="math">\(\nu\)</span> because the photon has a polarization. To get the probability amplitude, you actually have to contract the indices of the propagator with your desired polarization <span class="math">\(\varepsilon_\mu\)</span></p>
<p>But this is just the bare propagator, this is all tree-level. We want to compute what happens to the propagator when we include higher-order corrections. More practically: the fact that a photon can produce a virtual electron-positron pair, which then reannihilate into a photon, as such:</p>
<div class="figure">
<img src="images/one-floop.svg" title="one-loop" />
</div>
<p><em>should</em> affect the probability of the photon going from point A to point B. In fact, when summing over all possible diagrams for the <span class="math">\(\gamma\rightarrow \gamma\)</span> process:</p>
<p><span class="math">\(\Pi(q) = \)</span> <img src="images/dressed.svg" title="dressed" /> <span class="math">\(=\)</span> <img src="images/bare.svg" /> <span class="math">\(+\)</span> <img src="images/one-floop.svg" /> <span class="math">\(+\)</span> <img src="images/bibubble.svg" /> <span class="math">\(+\)</span> <img src="images/twobubble.svg" /> <span class="math">\(+ \ldots\)</span></p>
<p>we should get the &quot;dressed&quot;, or physical propagator <span class="math">\(\Pi^{\mu\nu}\)</span>. (A quick review of Feynman diagrams: time goes from left to right, wavy lines are photons, solid lines going right are electrons, left are positrons). Now we want to rearrange the terms of the previous series. Call a diagram one-particle-irreducible (1PI) if you cannot split it in two by cutting one of the internal lines (the two wavy lines at the beginning and end don't count). For example, the following diagrams are respectively 1PI and not 1PI.</p>
<p><img src="images/yesp.svg" />, <img src="images/twobubble.svg" /></p>
<p>Now consider the sum of all 1PI diagrams in the original series, and denote it as:</p>
<p><span class="math">\(S = \)</span> <img src="images/onepee.svg" /></p>
<p>My claim is that the full series of all diagrams for the photon propagator is equal to:</p>
<p><img src="images/dressed.svg" /> <span class="math">\(=\)</span> <img src="images/bare.svg" /> <span class="math">\(+\)</span> <img src="images/onepee.svg" /> <span class="math">\(+\)</span> <img src="images/twopee.svg" /> <span class="math">\(+\)</span> <img src="images/threepee.svg" /> <span class="math">\(+ \ldots\)</span></p>
<p>This is actually really simple. Think about it.</p>
<p>So, remembering that concatenating Feynman diagrams means we have to multiply them, we get the geometric series:</p>
<p><span class="math">\[ \Pi = \pi + \pi S \pi  + \pi S \pi S \pi + \pi S \pi S \pi S \pi + \ldots =  \pi\left( 1 + S\pi + (S\pi)^2 + (S\pi)^3 + \ldots \right)  \]</span></p>
<p>except these are matrices (with <span class="math">\(\mu\)</span> and <span class="math">\(\nu\)</span> indices), so we have to fix that before summing the geometric series. Here we introduce the fundamental Ward identity. If you have any process in which a photon is one of the external lines (incoming or outgoing particles), then the probability amplitude <span class="math">\(\mathcal{M}\)</span> satisfies</p>
<p><span class="math">\[ \mathcal{M}^\mu q_\mu = 0\]</span></p>
<p>where <span class="math">\(q_\mu\)</span> is the momentum of the photon.</p>
<p>Our 1PI propagator <span class="math">\(S^{\mu\nu}(q)\)</span> should satisfy the Ward identity. It must therefore be proportional to the projector on the subspace orthogonal to <span class="math">\(q_\mu\)</span>. It's not hard to convince oneself that this is given by</p>
<p><span class="math">\[ S^{\mu\nu}(q) = (q^2 g^{\mu\nu} - q^\mu q^\nu) \Phi(q^2) = \Delta^{\mu\nu}(q) \Phi(q^2) \]</span></p>
<p>Where <span class="math">\(\Phi(q^2)\)</span> is some scalar function (we also have used that the propagator must be Lorentz-invariant). Since <span class="math">\(\Delta\)</span> is a projector, <span class="math">\(\Delta^2 = \Delta\)</span> (in the sense of matrices). Moreover, also the product <span class="math">\(\Delta&#39; = \Delta \pi\)</span> is a projector, as you can readily compute. We return to our series:</p>
<p><span class="math">\[ \Pi(q) = \pi\left(1 + \Delta&#39; \Phi + \Delta&#39; \Phi^2 + \Delta&#39; \Phi^3 + \ldots \right) = \pi + \pi\left(\Delta&#39; \left( \frac{1}{1-\Phi(q)} - 1\right) \right) \]</span></p>
<p>So, finally</p>
<p><span class="math">\[ \Pi^{\mu\nu}(q) = \frac{-i}{q^2(1-\Phi(q^2))} \left(g^{\mu\nu} - \frac{q^\mu q^\nu}{q^2}\right) + \frac{-i}{q^2} \left( \frac{q^\mu q^\nu}{q^2} \right) \]</span></p>
<p>Now, we can just drop all terms with <span class="math">\(q_\mu q_\nu\)</span>, because the Ward identity tells us they will not contribute to the scattering amplitude (the Ward identity is just telling us that the longitudinal polarization of the photon is unphysical). Our final expression for the dressed propagator is</p>
<p><span class="math">\[ \Pi^{\mu\nu} = \frac{ -i g^{\mu\nu} } {q^2 (1-\Phi(q^2)) } \]</span></p>
<p>which is identical to our original bare propagator <span class="math">\(\pi\)</span>, just multiplied by the function <span class="math">\((1-\Phi(q^2))^{-1}\)</span>. Remembering what we said about poles and masses, for the photon mass to be preserved we would need that this function does not cancel the pole at <span class="math">\(q^2 = 0\)</span> of <span class="math">\(\pi\)</span>. The cancellation would need <span class="math">\(\Phi(q^2)\)</span> to have itself a second-order pole at <span class="math">\(q^2 = 0\)</span>, but this would seem impossible. However, it is absolutely not obvious, and in fact it is false in 2 spacetime dimensions. In the Schwinger model, in 2D, <span class="math">\(\Phi(0)\)</span> has a pole canceling <span class="math">\(q^2\)</span> and the photon mass is shifted to a finite value.</p>
<p>But our world is luckily higher-dimensional and the photon is safe from mass renormalization.</p>
<p>However, the propagator still acquires a global multiplicative factor</p>
<p><span class="math">\[ Z_3 := \frac{1}{1-\Pi(q^2)} \]</span></p>
<p>Since the photon propagator connects two interaction vertices, and these bring each a power of the fundamental charge <span class="math">\(e\)</span>, the quantum correction to the photon propagators is making the electromagnetic interaction stronger. In particular, for each photon line there are two vertices and one factor of <span class="math">\(Z_3\)</span>, so</p>
<p><span class="math">\[ e^2 \rightarrow Z_3 e^2 \]</span></p>
<p>which basically mean we could understand this shift as <span class="math">\(e \rightarrow \sqrt{Z_3} e\)</span>. This is why the procedure we performed above is called charge renormalization. We just derived the well-known fact that the strength of the EM interaction depends on the four-momenta involved.</p>
<p>To derive exactly that <span class="math">\(\Phi\)</span> has no unwanted pole and how exactly <span class="math">\(e(q^2)\)</span> runs with energy we would need to compute <span class="math">\(\Phi\)</span> explicitly (with some clever regularization, since it's divergent) and I don't want to do that. For that, refer to any good QFT/QED textbook.</p>
<h2 id="QG">Quantum Gravity/String Theory</h2>
<h3 id="QG1">QG1 - If the Planck length/Planck time is the smallest measurable/possible length/time, then...?</h3>
<p><em>to answer.</em></p>
<h2 id="list-of-well-known-crackpots">List of well-known crackpots</h2>
<h3 id="aether-wave-theory-zephir">Aether Wave Theory / Zephir</h3>
<p>Zephir is possibly the most beloved crackpot of the internet. He is famous for his erratic, colourful word salad style, immense persistence, and unshakable faith for the applicability of aether wave theory to every single question ever posed in history. His padronance of a huge lexicon of technical physics term, but complete ignorance on the meaning of each single word, have induced some people to believe Zephir is entirely or partly not human, but rather a Markov chain/recurrent neural network-like computer program.</p>
<ul>
<li>Zephir's story: <a href="https://www.reddit.com/r/badscience/comments/1m8u42/aether_wave_theory_and_zephir/">https://www.reddit.com/r/badscience/comments/1m8u42/aether_wave_theory_and_zephir/</a></li>
</ul>
<h3 id="imagining-the-tenth-dimension-rob-bryanton">Imagining the Tenth Dimension / Rob Bryanton</h3>
<p>Absolute shit. I'm actually afraid the guy is mentally ill.</p>
</body>
</html>
